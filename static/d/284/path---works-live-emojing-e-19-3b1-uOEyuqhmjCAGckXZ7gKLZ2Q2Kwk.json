{"data":{"site":{"siteMetadata":{"title":"diego dorado","author":"Diego Dorado"}},"markdownRemark":{"id":"d9393d7e-09e9-5098-9694-bd40eef92b29","excerpt":"Livecoding is a form of performatic art and a creative technique based upon the use of improvised interactive programming. It is often performed in live…","html":"<blockquote>\n<p><em>Livecoding is a form of performatic art and a creative technique based upon the use of improvised interactive programming. It is often performed in live presentations in which one or many Livecoders generate a progression of visuals and music displaying the code for the audience to see.</em></p>\n</blockquote>\n<p>Live-emojing is a Livecoding technique I developed with the intention of including the audience in the performance. Spectators input  patterns in an intuitive manner by sending series of <strong>emojis</strong> via social networks.</p>\n<p>\n  <span\n    class=\"gatsby-resp-image-wrapper\"\n    style=\"position: relative; display: block;  max-width: 1000px; margin-left: auto; margin-right: auto;\"\n  >\n    <span\n      class=\"gatsby-resp-image-background-image\"\n      style=\"padding-bottom: 66.54135338345864%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAACToAAAk6AGCYwUcAAADQElEQVQ4yz2TW08bVxSFz8x4PB5fxuPrGOMLxgZcjA3mYlBpKQkQTEpIaQuBBAgUGkXKSxsVJQ0SChJJoyhtlYhKjSqkqHlJr1Kee5GQ+pC39ql/oT/j67FN+3B09uw5e2vttdYWWiCOEAp2NU9y9gK6U0P3evHF0gh3AOGyEapJ2GlH9/jkW4HL8GEFw3i9/uZ3o751y6OdBgEnj1VeQcTHEbqNbqcp95f5+vNtxoa6SRYG8IUS2MEIh7f32Fm7ihEINWtVlxuhaK2GlqG2Aj2M0TPHO0uX2L70usy5WTtjwZ87HF4f/R/J8Gt9vPrhJ765f8hgvkDUL6fQ3Cia3kLq91uszpTp7R5AMSK8er7IP79dIZ8KYuiCjVoHnXETzWU2C6o9Jf7+5XdOnh1zbf5t+hIdWIYcXXXJ/xLcuUoAXs7w/EZXs2Dj3SEe3Twrx4ueolIlZwGc4gXM3DROJMF3Xz6hXqtx42KdmzPTGC7PKY/yxCyN/SWb995oNcgGTSbK3c04VSwxubCES9Ww0wNkJnZYnarT29NPf9Lh5PiI9cvriGgOYdotAAl3SyFDntGkzW66l1ImSySZZXv3gMr4FJYVIZ7K0d4/Ra1vDD3dRyadoTIygbCziFRJitEmx5Y8LnYJMraCpmlU2uJEA1GseBtrqx/woH4Z3392aKppovilzWJ5ygsfY3QOIULtqJEMwhuRSkseRwo2MW/DP5J0TSasKKFEO8MLo2SHO7i4vsD1K6ucGxzg3uYWy/VZ8slJXsz/TJczgvBIQTzSPrq8laZjXJg+A08ogGKVUEOSD2lgX0qiHX+TzY0P2Zl/n7ZalPy0Q+3sGHM9K/wYPGAiNCnfugkm8rjNYEsUw/ZgZoOondKYMT9aYyTboRIrkqvOcX7xKk8fPuHhV5+xfKdOcTKCWbCkqcNNGt6qDfLHt0fcXTlPxCM5dNtyVEugZCXcglwrXbreG6aWLJMbmmdr5Rov7j/g6M4+x5/e4q/Du7x8vMejvW1uSzqefrLJyRe73Jqr4XOpjY2RzQKSw2zDQ6c7qSpEI1nsXFkq6kgrGAhH5quC/KDN5myV7w8+4tfH+zzb3eLe8hmmi6lm7b/TE4NO5FS6BAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n    >\n      <img\n        class=\"gatsby-resp-image-image\"\n        style=\"width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;\"\n        alt=\"cover\"\n        title=\"\"\n        src=\"/static/96c410efdf15592e9c9bfa1512d62a61/0f755/cover.png\"\n        srcset=\"/static/96c410efdf15592e9c9bfa1512d62a61/88890/cover.png 250w,\n/static/96c410efdf15592e9c9bfa1512d62a61/99ef7/cover.png 500w,\n/static/96c410efdf15592e9c9bfa1512d62a61/0f755/cover.png 1000w,\n/static/96c410efdf15592e9c9bfa1512d62a61/aaaad/cover.png 1500w,\n/static/96c410efdf15592e9c9bfa1512d62a61/596b5/cover.png 2000w,\n/static/96c410efdf15592e9c9bfa1512d62a61/c4f57/cover.png 3000w,\n/static/96c410efdf15592e9c9bfa1512d62a61/79255/cover.png 4256w\"\n        sizes=\"(max-width: 1000px) 100vw, 1000px\"\n      />\n    </span>\n  </span>\n  </p>\n<p>Besides my interest  in having the audience participate in the performance, I have the intention of bringing down the idea that programming is inaccessible. Socializing the code by inviting the spectator to intervene.</p>\n<p>I found in <strong>emojis</strong> a key to attract the public to reading the code. It’s appeal comes as a result of it being both a very familiar element and at the same time very antinatural to programming languages. <em>This contrast makes it stand out.</em></p>\n<blockquote>\n<p><strong>Emojis communicate quickly, easy and make no language distinction.</strong></p>\n</blockquote>\n<hr>\n<h3>Some Performances</h3>\n<p>Streaming with interaction via Telegram\n<div>\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.49999999999999%; position: relative; height: 0; overflow: hidden;margin-bottom: 1.0725rem\"\n          >\n            <div class=\"embedVideo-container\">\n            <iframe src=\"https://www.youtube.com/embed/OwKUuypxP6Y?rel=0\" class=\"embedVideo-iframe\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n        </div>\n      <style>\n        .embedVideo-iframe {\n          border: 0\n        }\n      </style>\n          </div>\n          </div></p>\n<br/>\n<p><div>\n          <div\n            class=\"gatsby-resp-iframe-wrapper\"\n            style=\"padding-bottom: 56.49999999999999%; position: relative; height: 0; overflow: hidden;margin-bottom: 1.0725rem\"\n          >\n            <div class=\"embedVideo-container\">\n            <iframe src=\"https://www.youtube.com/embed/6HVmAN7bScQ?rel=0\" class=\"embedVideo-iframe\" allowfullscreen style=\"\n            position: absolute;\n            top: 0;\n            left: 0;\n            width: 100%;\n            height: 100%;\n          \"></iframe>\n        </div>\n      <style>\n        .embedVideo-iframe {\n          border: 0\n        }\n      </style>\n          </div>\n          </div>\n<em>Performance at “Centro Cultural Recoleta” on 2018 world emoji day</em></p>\n<p>Motivation:</p>\n<p>My interest to make the audience take part in the livecoding experience brought to me the idea of “livecoding with emojis“</p>\n<p>I had previously tried to reach out for such interaction by other means.</p>\n<p>Enlarging the font to its maximum size so that reading the code would be comfortable to the audience.</p>\n<p>Larger font size invites us to reading it.</p>\n<p>Starting out from a blank page with simple sequences that were easy to relate to the audio being generated and gradually becoming more complex.</p>\n<p>The blank sheet generates a lot of curiosity and gives an opportunity to try to follow the initial logical sequences</p>\n<p>Code Localization. I created aliases in our native language of some function names or code blocks to replace their original English names as a way to engage Non-English speakers during presentations.</p>\n<p>Displaying the code written in native language draws attention, eliminates the difficulty of the language barrier and focuses attention on what the code is really about.</p>\n<p>Proof of Concept</p>\n<p>Initially I wrote a haskell function to map 7 emojis to 7 different samples in tidalcycles’ livecoding environment.\nIn this first proof of concept the emojis were not received but rather typed in the Atom editor (thanks to the autocomplete-emojis package)</p>\n<p>Emojis mapping function in Tidalcycles</p>\n<p>Including Telegram</p>\n<p>I thought then that it would be fun to receive the emojis from the public, so I created a Telegram bot to interact with the audience.</p>\n<p>I developed an Atom plugin to handle messages received by the bot. These messages were automatically inserted by the plugin in certain positions of the editor.\nThese positions would remain occupied for 30 seconds by the same person(message). A countdown would urged them to continue the game by updating the pattern or risk that someone else takes their place.</p>\n<p>The bot starts the conversation with a message explaining the rules of the game</p>\n<p>Upon receipt of a message, the bot would include it in the presentation and a possible tidalcycles pattern translation of the message would be responded to the sender.</p>\n<p>Including Facebook</p>\n<p>As I usually streamed the performance through Facebook, several people who did not knew about Telegram sent me the emojis via facebook chat. I understood that it would be a simpler process for the audience to participate by using those Facebook messages rather than asking them to install Telegram and write to the bot.</p>\n<p>So, I wrote a Chrome extension that would scrape the Facebook page looking for messages containing emojis in the streaming chat and send them back to the Atom plugin via websockets.</p>\n<p>You can see the comment by Damian Silvani appear in streaming video, next to his name</p>\n<p>In this way, a spectator, present in the audience or following the stream remotely, could send an “emoji algorithm” via Telegram or via Facebook and see the contribution next to his or her user name projected (or streamed) live.</p>\n<p>Eventually, even someone without any livecoding experience could relate the pattern of emojis sent with the pattern of sounds being generated  by that intervention.\nThis last point would be an educational path of minimum difficulty with the objective of   introducing someone to the idea of programming applied to art.</p>\n<p>Including Reactive Visuals</p>\n<p>Once the interaction with the spectator was completed, I continued to develop a better graphic representation of the patterns with the intention of making it even clearer and more attractive.\nI included in the session a 3D scenario that runs as background to the editor and that responds visually to each sound event generated by the emoji patterns. This further facilitates the relationship between the sent emojis and the generated sounds.</p>\n<p>About emoji to sample mapping</p>\n<p>It is not possible to foresee the emojis that I would receive. Initially I took the decision of using  the unicode value of the emoji as the index to be played from a folder of samples (strictly speaking, the rest of the division by the number of possible samples). This was comfortable, but not very useful, since the samples were repeated very often and it was not possible to guess the sound to be played.</p>\n<p>I started working on an alternative. Mapping all existing emojis was too much work. Someone must have made a list of the most popular emojis. I found something much better: emojitracker.com, a site that tracks the emojis used on twitter in real time and ranks them.\nI then took the most popular emojis and began to do a manual mapping, in a JSON file still in development, in which I grouped them by similarity.</p>\n<p>The goal is to achieve a correspondence between what the emoji represents visually and sonorously.\nCurrently, this correspondence is totally arbitrary, for example,\nhearts sound like bass drums\nopen hands sound like claps\nfists sound like snare drums\nlaughing faces sound like hi hats\nopen mouths faces sound like chants</p>\n<p>This makes it easier to understand how the emoji pattern sent should sound and to recognize that   *4     is similar (or equal) to    *4   </p>\n<p>Future expectations:</p>\n<p>I plan to continue with the development of these tools and take them to other environments. I have already done some tests on FoxDot.\nI think they can be highly educational in the field of programming, as an introductory approach and as a means of spreading the practice of livecoding.\nDue to the experience so far and the possibilities of extending this tool, I envision a new expressive medium to explore.\nI am working to publish the repositories of these plugins with their respective documentation and instructions with certainty that new and interesting applications will emerge from their disclosure.</p>\n<p>And above all: continue with performances of this type that I find extremely fun.</p>","frontmatter":{"title":"Live-Emojing","date":"May 28, 2019","description":"Livecoding technique I developed with the intention of including the audience in the performance. Spectators input  patterns in an intuitive manner by sending series of emojis via social networks."}}},"pageContext":{"slug":"/works/live-emojing/","previous":{"fields":{"slug":"/works/human-aided-music/","type":"works"},"frontmatter":{"title":"Human Aided Music"}},"next":null}}